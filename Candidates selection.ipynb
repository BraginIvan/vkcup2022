{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc5da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pnd\n",
    "import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d58ad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = \"final/data/label.csv\"\n",
    "train_path = \"final/data/ego_net_tr.csv\"\n",
    "test_path = \"final/data/ego_net_te.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f24336c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label(label_path):\n",
    "    with open(label_path, 'r') as label_f:\n",
    "        label_f.readline()\n",
    "        cur_ego_id = -1\n",
    "        cur_label = None\n",
    "        for line in label_f:\n",
    "            ego_id, u, v = list(map(int, line.split(\",\")))\n",
    "            if ego_id != cur_ego_id:\n",
    "                if cur_ego_id != -1:\n",
    "                    yield cur_ego_id, cur_label\n",
    "                cur_ego_id, cur_label = ego_id, []\n",
    "            cur_label.append((u, v))\n",
    "        if cur_ego_id != -1 and len(cur_label) > 0:\n",
    "            yield cur_ego_id, cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca291f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ego_net(ego_net_path):\n",
    "    cur_ego_id = -1\n",
    "    cur_ego_net = None\n",
    "    with open(ego_net_path, 'r') as ego_net_f:\n",
    "        ego_net_f.readline()\n",
    "        for ego_line in ego_net_f:\n",
    "            ego_line = ego_line.split(',')\n",
    "            ego_id, u, v, t, x1, x2, x3 = int(ego_line[0]), int(ego_line[1]), int(ego_line[2]), int(ego_line[3]), float(ego_line[4]), float(ego_line[5]), float(ego_line[6])\n",
    "            if ego_id != cur_ego_id:\n",
    "                if cur_ego_id != -1:\n",
    "                    yield cur_ego_id, cur_ego_net\n",
    "                assert cur_ego_id <= ego_id\n",
    "                cur_ego_id = ego_id\n",
    "                cur_ego_net = nx.DiGraph()\n",
    "            if u not in cur_ego_net:\n",
    "                cur_ego_net.add_node(u)\n",
    "            if v not in cur_ego_net:\n",
    "                cur_ego_net.add_node(v)\n",
    "            cur_ego_net.add_edge(u, v, t=t, x1=x1, x2=x2, x3=x3)\n",
    "        if cur_ego_net.size() > 0 and cur_ego_id != -1:\n",
    "            yield cur_ego_id, cur_ego_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586fe3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(ego_net):\n",
    "    E = ego_net.edges\n",
    "    mtr = nx.to_numpy_array(ego_net)\n",
    "    mtr[0, :] = 0\n",
    "    mtr[:, 0] = 0\n",
    "    mtr1 = (mtr + mtr.T)/2\n",
    "    mtr2 = (mtr + mtr.T)/2\n",
    "#     time_connects = mtr\n",
    "    mtr_x1 = np.zeros_like(mtr1)\n",
    "    mtr_x2 = np.zeros_like(mtr1)\n",
    "    mtr_x3 = np.zeros_like(mtr1)\n",
    "\n",
    "    for x in E:\n",
    "        mtr_x1[x[0], x[1]] = E[x][\"x1\"]\n",
    "        mtr_x2[x[0], x[1]] = E[x][\"x2\"]\n",
    "        mtr_x3[x[0], x[1]] = E[x][\"x3\"]\n",
    "        if E[x][\"t\"] == -1:\n",
    "            t = 10000000\n",
    "        else:\n",
    "            t = E[x][\"t\"]\n",
    "        mtr1[x[0], x[1]] *= 1/np.log(((t/25)**2)+2)  + np.log(E[x][\"x1\"] +1)*0.2 + np.log(E[x][\"x2\"] +1)*0.2+ np.log(E[x][\"x3\"] +1)*0.5\n",
    "        mtr2[x[0], x[1]] *= 1/np.log(((t/18)**2)+2)  + np.log(E[x][\"x1\"] +1)*0.2 + np.log(E[x][\"x2\"] +1)*0.2+ np.log(E[x][\"x3\"] +1)*0.5\n",
    "    out_degree = mtr.sum(axis=1).reshape((-1, 1))\n",
    "\n",
    "    mtr_x1_weight = mtr_x1.T.dot(mtr1) * (1 - 100 * np.eye(len(mtr2)))  * (1 - 100 * mtr1)\n",
    "    mtr_x2_weight = mtr_x2.T.dot(mtr1) * (1 - 100 * np.eye(len(mtr2)))  * (1 - 100 * mtr1)\n",
    "    mtr_x3_weight = mtr_x3.T.dot(mtr1) * (1 - 100 * np.eye(len(mtr2)))  * (1 - 100 * mtr1)\n",
    "\n",
    "\n",
    "    mtr_norm = (mtr / (1 + np.log(1 + out_degree)))\n",
    "    mtr1_norm = (mtr1 / (1 + np.log(1 + out_degree)))\n",
    "    mtr2_norm = (mtr2 / (1 + np.log(1 + out_degree)))\n",
    "\n",
    "    aa = mtr_norm.T.dot(mtr1_norm) * (1 - 100 * np.eye(len(mtr1))) * (1 - 100 * mtr1)\n",
    "    aa += mtr_norm.T.dot(mtr2_norm) * (1 - 100 * np.eye(len(mtr1))) * (1 - 100 * mtr1)\n",
    "    \n",
    "    mtr_x1_weight = np.mean([mtr_x1_weight, mtr_x1_weight.T], axis=0)    \n",
    "    mtr_x2_weight = np.mean([mtr_x2_weight, mtr_x2_weight.T], axis=0)    \n",
    "    mtr_x3_weight = np.mean([mtr_x3_weight, mtr_x3_weight.T], axis=0)    \n",
    "    \n",
    "\n",
    "    aa += mtr_x1_weight*0.05\n",
    "    aa += mtr_x2_weight*0.01\n",
    "    aa += mtr_x3_weight*0.05\n",
    "    \n",
    "    aa = np.mean([aa, aa.T], axis=0)    \n",
    "\n",
    "    recs = list()\n",
    "    for i in aa.flatten().argsort()[::-1]:\n",
    "        u, v = min(i // len(mtr), i % len(mtr)), max(i // len(mtr), i % len(mtr))\n",
    "        \n",
    "        if u < v and u != 0 and (u,v) not in recs:\n",
    "            recs.append((u, v))\n",
    "        if len(recs) == 1000:\n",
    "            break\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbee662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [01:19, 12.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "142it [00:12, 11.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    n = 0\n",
    "    ndcgs = []\n",
    "    recalls = []\n",
    "    with open('val.csv', 'w') as out:\n",
    "        out.write('ego_id,u,v,label\\n')\n",
    "        recalls = []\n",
    "        for (ego_id1, ego_net), (ego_id2, label) in tqdm.tqdm(zip(read_ego_net(train_path), read_label(labels_path))):\n",
    "            assert ego_id1 == ego_id2\n",
    "            recs = recommend(ego_net)\n",
    "            if len([x for x in label if x in recs]) == 0:\n",
    "                recalls.append(0)\n",
    "            else:\n",
    "                for u, v in recs:\n",
    "                    l = \"1\" if (u,v) in label else \"0\"\n",
    "                    out.write('{},{},{},{}\\n'.format(ego_id1, u, v, l))\n",
    "                recalls.append(1)\n",
    "            if len(recalls) % 1000  == 0:\n",
    "                print(np.mean(recalls))\n",
    "    with open('test.csv', 'w') as out:\n",
    "        out.write('ego_id,u,v,label\\n')\n",
    "        for ego_id1, ego_net in tqdm.tqdm(read_ego_net(test_path)):\n",
    "            recs = recommend(ego_net)\n",
    "            for u, v in recs:\n",
    "                out.write('{},{},{},{}\\n'.format(ego_id1, u, v, -1))\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fb4a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "deafeb27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02346f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds1000 = pd.read_csv('test.csv')\n",
    "test_preds1000['i'] = test_preds1000.index\n",
    "test_preds1000[\"rank\"] = test_preds1000.groupby(\"ego_id\")[\"i\"].rank(method=\"dense\")\n",
    "test_preds1000[\"rank\"] = test_preds1000[\"rank\"].apply(lambda x: int(x))\n",
    "test_preds1000.to_csv('test_rank.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a528b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds1000 = pd.read_csv('val.csv')\n",
    "test_preds1000['i'] = test_preds1000.index\n",
    "test_preds1000[\"rank\"] = test_preds1000.groupby(\"ego_id\")[\"i\"].rank(method=\"dense\")\n",
    "test_preds1000[\"rank\"] = test_preds1000[\"rank\"].apply(lambda x: int(x))\n",
    "test_preds1000.to_csv('val_rank.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298c105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d32b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/12 19:57:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/12 19:57:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "<SparkContext master=local[1] appName=SparkByExamples.com>\n",
      "Spark App Name : SparkByExamples.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()\n",
    "print(spark.sparkContext)\n",
    "print(\"Spark App Name : \"+ spark.sparkContext.appName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9a27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType,BooleanType,DoubleType,LongType\n",
    "\n",
    "for table in ['test_rank', 'val_rank']:\n",
    "    train_pairs_recall = spark.read.csv(f\"{table}.csv\", header=True)\n",
    "    train_pairs_recall = train_pairs_recall.withColumn(\"ego_id\",F.col(\"ego_id\").cast(LongType()))\\\n",
    "    .drop('i')\\\n",
    "    .withColumn(\"u\",F.col(\"u\").cast(IntegerType()))\\\n",
    "    .withColumn(\"v\",F.col(\"v\").cast(IntegerType()))\\\n",
    "    .withColumn(\"rank\",F.col(\"rank\").cast(IntegerType()))\\\n",
    "    .withColumn(\"label\",F.col(\"label\").cast(IntegerType())).write.parquet(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f12910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
